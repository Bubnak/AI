{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03bbbff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /Users/bubnak/anaconda3/lib/python3.11/site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (4.66.5)\n",
      "Requirement already satisfied: protobuf in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (4.25.4)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'transformers[sentencepiece]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091528ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/bubnak/anaconda3/lib/python3.11/site-packages (0.34.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n",
      "Found existing installation: transformers 4.40.0\n",
      "Uninstalling transformers-4.40.0:\n",
      "  Successfully uninstalled transformers-4.40.0\n",
      "Found existing installation: accelerate 0.34.2\n",
      "Uninstalling accelerate-0.34.2:\n",
      "  Successfully uninstalled accelerate-0.34.2\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Requirement already satisfied: filelock in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n",
      "Installing collected packages: huggingface-hub, accelerate, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.22.2\n",
      "    Uninstalling huggingface-hub-0.22.2:\n",
      "      Successfully uninstalled huggingface-hub-0.22.2\n",
      "Successfully installed accelerate-0.34.2 huggingface-hub-0.25.0 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate\n",
    "!pip uninstall -y transformers accelerate\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1d3c252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/bubnak/anaconda3/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: filelock in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (0.25.0)\n",
      "Requirement already satisfied: packaging in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.22.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5087c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py7zr\n",
      "  Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting texttable (from py7zr)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pycryptodomex>=3.16.0 (from py7zr)\n",
      "  Using cached pycryptodomex-3.20.0-cp35-abi3-macosx_10_9_x86_64.whl (1.6 MB)\n",
      "Collecting pyzstd>=0.15.9 (from py7zr)\n",
      "  Downloading pyzstd-0.16.1-cp311-cp311-macosx_10_9_x86_64.whl (372 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.2/372.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n",
      "  Downloading pyppmd-1.1.0-cp311-cp311-macosx_10_9_x86_64.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading pybcj-1.0.2-cp311-cp311-macosx_10_9_x86_64.whl (23 kB)\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading inflate64-1.0.0-cp311-cp311-macosx_10_9_x86_64.whl (36 kB)\n",
      "Collecting brotli>=1.1.0 (from py7zr)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-macosx_10_9_x86_64.whl (446 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.2/446.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from py7zr) (5.9.0)\n",
      "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n",
      "Successfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.16.1 texttable-1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c684971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/bubnak/anaconda3/lib/python3.11/site-packages (0.4.3)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (0.25.0)\n",
      "Requirement already satisfied: packaging in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: absl-py in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from rouge_score) (2.0.0)\n",
      "Requirement already satisfied: nltk in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: filelock in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: click in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/bubnak/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=3ddae6172e69eda26e3de6341826be441348b7c48f9737b788e22fe77d299692\n",
      "  Stored in directory: /Users/bubnak/Library/Caches/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61cddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2612642",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e4b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac34537",
   "metadata": {},
   "source": [
    "### Load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c41fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = \"google/pegasus-cnn_dailymail\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111e776",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f72b82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\")\n",
    "dataset_samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdff6cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14727</th>\n",
       "      <td>13863028</td>\n",
       "      <td>Romeo: You are on my ‘People you may know’ lis...</td>\n",
       "      <td>Romeo is trying to get Greta to add him to her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14728</th>\n",
       "      <td>13828570</td>\n",
       "      <td>Theresa: &lt;file_photo&gt;\\r\\nTheresa: &lt;file_photo&gt;...</td>\n",
       "      <td>Theresa is at work. She gets free food and fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14729</th>\n",
       "      <td>13819050</td>\n",
       "      <td>John: Every day some bad news. Japan will hunt...</td>\n",
       "      <td>Japan is going to hunt whales again. Island an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14730</th>\n",
       "      <td>13828395</td>\n",
       "      <td>Jennifer: Dear Celia! How are you doing?\\r\\nJe...</td>\n",
       "      <td>Celia couldn't make it to the afternoon with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14731</th>\n",
       "      <td>13729017</td>\n",
       "      <td>Georgia: are you ready for hotel hunting? We n...</td>\n",
       "      <td>Georgia and Juliette are looking for a hotel i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14732 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                           dialogue  \\\n",
       "0      13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
       "1      13728867  Olivia: Who are you voting for in this electio...   \n",
       "2      13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n",
       "3      13730747  Edward: Rachel, I think I'm in ove with Bella....   \n",
       "4      13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n",
       "...         ...                                                ...   \n",
       "14727  13863028  Romeo: You are on my ‘People you may know’ lis...   \n",
       "14728  13828570  Theresa: <file_photo>\\r\\nTheresa: <file_photo>...   \n",
       "14729  13819050  John: Every day some bad news. Japan will hunt...   \n",
       "14730  13828395  Jennifer: Dear Celia! How are you doing?\\r\\nJe...   \n",
       "14731  13729017  Georgia: are you ready for hotel hunting? We n...   \n",
       "\n",
       "                                                 summary  \n",
       "0      Amanda baked cookies and will bring Jerry some...  \n",
       "1      Olivia and Olivier are voting for liberals in ...  \n",
       "2      Kim may try the pomodoro technique recommended...  \n",
       "3      Edward thinks he is in love with Bella. Rachel...  \n",
       "4      Sam is confused, because he overheard Rick com...  \n",
       "...                                                  ...  \n",
       "14727  Romeo is trying to get Greta to add him to her...  \n",
       "14728  Theresa is at work. She gets free food and fre...  \n",
       "14729  Japan is going to hunt whales again. Island an...  \n",
       "14730  Celia couldn't make it to the afternoon with t...  \n",
       "14731  Georgia and Juliette are looking for a hotel i...  \n",
       "\n",
       "[14732 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset_samsum['train'])\n",
    "\n",
    "pd.DataFrame(dataset_samsum['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239751c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dialogue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c76932a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amanda baked cookies and will bring Jerry some tomorrow.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087758a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
    "\n",
    "    return {\n",
    "        'input_ids' : input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0872ce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71006e586d1e4921be0a2755fc1c1e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bubnak/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51d0228a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9045e7f",
   "metadata": {},
   "source": [
    "### Evaluate pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d195d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = [[(label if label != -100 else tokenizer.pad_token_id) for label in label] for label in labels]\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    result = {key: value * 100 for key, value in result.items()}  # Return as percentage\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "058b0638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='819' max='819' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [819/819 3:16:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6421968936920166, 'eval_model_preparation_time': 0.0068, 'eval_rouge1': 29.611979328327287, 'eval_rouge2': 8.661650459308024, 'eval_rougeL': 22.759076833540576, 'eval_rougeLsum': 22.785841247859253, 'eval_runtime': 11831.5275, 'eval_samples_per_second': 0.069, 'eval_steps_per_second': 0.069}\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model_pegasus,\n",
    "    args=training_args,\n",
    "    eval_dataset=dataset_samsum_pt['test'],  # Use the test or validation split\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2c578",
   "metadata": {},
   "source": [
    "### Fine tune pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "456f3a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [920/920 14:37:26, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.665800</td>\n",
       "      <td>1.484593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./tokenizer/tokenizer_config.json',\n",
       " './tokenizer/special_tokens_map.json',\n",
       " './tokenizer/spiece.model',\n",
       " './tokenizer/added_tokens.json',\n",
       " './tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\n",
    "trainer_args = TrainingArguments(\n",
    "        output_dir='pegasus-samsum', \n",
    "        num_train_epochs=1, \n",
    "        warmup_steps=500,\n",
    "        per_device_train_batch_size=1, \n",
    "        per_device_eval_batch_size=1,\n",
    "        weight_decay=0.01, \n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='steps', \n",
    "        eval_steps=500,  \n",
    "        save_steps=1e6,\n",
    "        gradient_accumulation_steps=16\n",
    "  )\n",
    "\n",
    "trainer = Trainer(\n",
    "            model=model_pegasus, \n",
    "            args=trainer_args,\n",
    "            tokenizer=tokenizer, \n",
    "            data_collator=seq2seq_data_collator,\n",
    "            train_dataset=dataset_samsum_pt[\"train\"], \n",
    "            eval_dataset=dataset_samsum_pt[\"validation\"])\n",
    "  \n",
    "trainer.train()\n",
    "\n",
    "model_pegasus.save_pretrained(\"./pegasus-samsum-model\")\n",
    "tokenizer.save_pretrained(\"./tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c9299",
   "metadata": {},
   "source": [
    "### Evaluate fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "794032d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='819' max='819' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [819/819 1:57:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4537464380264282, 'eval_model_preparation_time': 0.0067, 'eval_rouge1': 45.04982150447816, 'eval_rouge2': 21.415838982179483, 'eval_rougeL': 35.38904089651658, 'eval_rougeLsum': 35.385210562522005, 'eval_runtime': 7085.8272, 'eval_samples_per_second': 0.116, 'eval_steps_per_second': 0.116}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./pegasus-samsum-model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    per_device_eval_batch_size=1, \n",
    "    predict_with_generate=True,  \n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=dataset_samsum_pt['test'],  # Pass your validation set dataset_samsum_pt[\"validation\"]\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "finetuned_results = trainer.evaluate()\n",
    "\n",
    "print(finetuned_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450976b9",
   "metadata": {},
   "source": [
    "### Compare difference before and after the fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2c7167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in eval_loss: -1.19\n",
      "Change in eval_rouge1: 15.44\n",
      "Change in eval_rouge2: 12.75\n",
      "Change in eval_rougeL: 12.63\n"
     ]
    }
   ],
   "source": [
    "for key in metrics_before:\n",
    "    print(f\"Change in {key}: {finetuned_results[key] - eval_results[key]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091c5f9",
   "metadata": {},
   "source": [
    "### Generate output from fined tuned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8864e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: Docker is listening on all available network interfaces. The container can accept connections from any IP address on the host machine.<n>Docker port is set to 8080.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./pegasus-samsum-model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\")\n",
    "\n",
    "input_text = \"Yes, that's correct! When you run a Docker container and bind it to 0.0.0.0:8080, it means: Docker is listening on all available network interfaces: The container can accept connections from any IP address on the host machine.Docker port is set to 8080: This is the port on the host machine that is mapped to the port your application is running on inside the container (for example, if your Flask app is running on port 5000 inside the container, you would typically run the container with -p 8080:5000.So, any requests sent to  will be routed to the application running in the Docker container.The your-host-ip would typically refer to the IP address of the machine where Docker is running. If you're running everything locally (like on your development machine), you can use localhost or 127.0.0.1.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=128, early_stopping=True)\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba4a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
